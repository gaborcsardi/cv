[{"path":"/articles/cv.html","id":"cross-validation","dir":"Articles","previous_headings":"","what":"Cross-validation","title":"Cross-validation of regression models","text":"Cross-validation (CV) essentially simple intuitively reasonable approach estimating predictive accuracy regression models. CV developed many standard sources regression modeling “machine learning”—particularly recommend James, Witten, Hastie, & Tibshirani (2021, secs. 5.1, 5.3)—describe method briefly taking computational issues examples. Validating research replication independently collected data common scientific norm. Emulating process single study data-division less common: data randomly divided two, possibly equal-size, parts; first part used develop fit statistical model; second part used assess adequacy model fit first part data. Data-division, however, suffers two problems: (1) Dividing data decreases sample size thus increases sampling error; (2), even disconcertingly, particularly smaller samples, results can vary substantially based random division data: See Harrell (2015, sec. 5.3) remarks data-division cross-validation. Cross-validation speaks issues. CV, data randomly divided equally possible several, say \\(k\\), parts, called “folds.” statistical model fit \\(k\\) times, leaving fold turn. fitted model used predict response variable omitted fold, computing CV criterion “cost” measure, mean-squared error prediction. CV criterion averaged \\(k\\) folds. extreme \\(k = n\\), number cases data, thus omitting individual cases refitting model \\(n\\) times—procedure termed “leave-one-(LOO) cross-validation.” \\(k\\) models fit \\(n - 1\\) cases, LOO CV produces nearly unbiased estimate prediction error. \\(n\\) regression models highly statistical dependent, however, based nearly data, resulting estimate prediction error relatively large variance. contrast, estimated prediction error \\(k\\)-fold CV \\(k = 5\\) \\(10\\) (commonly employed choices) somewhat biased smaller variance. also possible correct \\(k\\)-fold CV bias (see ).","code":""},{"path":[]},{"path":"/articles/cv.html","id":"polynomial-regression-for-the-auto-data","dir":"Articles","previous_headings":"Examples","what":"Polynomial regression for the Auto data","title":"Cross-validation of regression models","text":"data example drawn ISLR2 package R, associated James et al. (2021), presentation close (though identical) original source (James et al., 2021, secs. 5.1, 5.3), demonstrates use cv() function cv package.1 Auto dataset contains information 392 cars: exception origin (’ll address later), variables largely self-explanatory, possible exception units measurement: details see help(\"Auto\", package=\"ISLR2\"). ’ll focus relationship mpg (miles per gallon) horsepower, displayed following scatterplot: mpg vs horsepower Auto data relationship two variables monotone, decreasing, nonlinear. Following James et al. (2021), ’ll consider approximating relationship polynomial regression, degree polynomial \\(p\\) ranging 1 (linear regression) 10.2 Polynomial fits \\(p = 1\\) \\(5\\) shown following figure: mpg vs horsepower Auto data linear fit clearly inappropriate; fits \\(p = 2\\) (quadratic) \\(4\\) similar; fit \\(p = 5\\) probably -fits data chasing one two relatively high mpg values right. following graph shows two measures estimated squared error function polynomial-regression degree: mean-squared error (MSE), defined \\(\\mathsf{MSE} = \\sum (y_i - \\widehat{y}_i)^2/n\\), usual unbiased estimated error variance, defined \\(\\widehat(\\sigma)^2 = \\sum (y_i - \\widehat{y}_i)^2/(n - p - 1)\\). former necessarily declines \\(p\\) (, strictly, can’t increase \\(p\\)), latter gets slightly larger largest values \\(p\\), “best” value, small margin, \\(p = 7\\). Estimated squared error function polynomial degree, \\(p\\) code graph uses mse() function cv package compute MSE fit.","code":"data(\"Auto\", package=\"ISLR2\") head(Auto) #>   mpg cylinders displacement horsepower weight acceleration year origin #> 1  18         8          307        130   3504         12.0   70      1 #> 2  15         8          350        165   3693         11.5   70      1 #> 3  18         8          318        150   3436         11.0   70      1 #> 4  16         8          304        150   3433         12.0   70      1 #> 5  17         8          302        140   3449         10.5   70      1 #> 6  15         8          429        198   4341         10.0   70      1 #>                        name #> 1 chevrolet chevelle malibu #> 2         buick skylark 320 #> 3        plymouth satellite #> 4             amc rebel sst #> 5               ford torino #> 6          ford galaxie 500 dim(Auto) #> [1] 392   9 plot(mpg ~ horsepower, data=Auto) plot(mpg ~ horsepower, data=Auto) horsepower <- with(Auto,                     seq(min(horsepower), max(horsepower),                         length=1000)) for (p in 1:5){   m <- lm(mpg ~ poly(horsepower,p), data=Auto)   mpg <- predict(m, newdata=data.frame(horsepower=horsepower))   lines(horsepower, mpg, col=p + 1, lty=p, lwd=2) } legend(\"topright\", legend=1:5, col=2:6, lty=1:5, lwd=2,        title=\"Degree\", inset=0.02) se <- mse <- numeric(10) for (p in 1:10){   m <- lm(mpg ~ poly(horsepower, p), data=Auto)   mse[p] <- mse(Auto$mpg, fitted(m))   se[p] <- summary(m)$sigma }  plot(c(1, 10), range(mse, se^2), type=\"n\",      xlab=\"Degree of polynomial, p\",      ylab=\"Estimated Squared Error\") lines(1:10, mse, lwd=2, lty=1, col=2, pch=16, type=\"b\") lines(1:10, se^2, lwd=2, lty=2, col=3, pch=17, type=\"b\") legend(\"topright\", inset=0.02,        legend=c(expression(hat(sigma)^2), \"MSE\"),        lwd=2, lty=2:1, col=3:2, pch=17:16)"},{"path":"/articles/cv.html","id":"using-cv","dir":"Articles","previous_headings":"Examples > Polynomial regression for the Auto data","what":"Using cv()","title":"Cross-validation of regression models","text":"generic cv() function \"lm\" method, default performs \\(k = 10\\)-fold CV: \"lm\" method default uses mse() CV criterion Woodbury matrix identity update regression fold deleted without literally refit model. Computational details discussed final section vignette. function reports CV estimate MSE, biased-adjusted estimate MSE (bias adjustment explained final section), MSE also computed original, full-sample regression. division data 10 folds random, cv() explicitly (randomly) generates saves seed R’s pseudo-random number generator, make results replicable. user can also specify seed directly via seed argument cv(). perform LOO CV, can set k argument cv() number cases data, k=392, , conveniently, k=\"loo\" k=\"n\": LOO CV linear model, cv() default uses hatvalues model fit full data LOO updates, reports CV estimate MSE. Alternative methods use Woodbury matrix identity “naive” approach literally refitting model case omitted. three methods produce exact results linear model (within precision floating-point computations): \"naive\" \"Woodbury\" methods also return bias-adjusted estimate MSE full-sample MSE, bias isn’t issue LOO CV. small regression problem three computational approaches essentially instantaneous, still interest investigate relative speed. comparison, include cv.glm() function boot package, takes naive approach, fit linear model equivalent Gaussian GLM. use microbenchmark() function package name timings (Mersmann, 2023): computer, using hatvalues order magnitude faster employing Woodbury matrix updates, two orders magnitude faster refitting model.3","code":"m.auto <- lm(mpg ~ poly(horsepower, 2), data=Auto) summary(m.auto) #>  #> Call: #> lm(formula = mpg ~ poly(horsepower, 2), data = Auto) #>  #> Residuals: #>     Min      1Q  Median      3Q     Max  #> -14.714  -2.594  -0.086   2.287  15.896  #>  #> Coefficients: #>                      Estimate Std. Error t value Pr(>|t|)     #> (Intercept)            23.446      0.221   106.1   <2e-16 *** #> poly(horsepower, 2)1 -120.138      4.374   -27.5   <2e-16 *** #> poly(horsepower, 2)2   44.090      4.374    10.1   <2e-16 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> Residual standard error: 4.37 on 389 degrees of freedom #> Multiple R-squared:  0.688,  Adjusted R-squared:  0.686  #> F-statistic:  428 on 2 and 389 DF,  p-value: <2e-16  cv(m.auto) #> 10-Fold Cross Validation #> method: Woodbury #> criterion: mse #> cross-validation criterion = 19.196 #> bias-adjusted cross-validation criterion = 19.185 #> full-sample criterion = 18.985 cv(m.auto, k=\"loo\") #> n-Fold Cross Validation #> method: hatvalues #> criterion: mse #> cross-validation criterion = 19.248 cv(m.auto, k=\"loo\", method=\"naive\") #> n-Fold Cross Validation #> method: naive #> criterion: mse #> cross-validation criterion = 19.248 #> bias-adjusted cross-validation criterion = 19.248 #> full-sample criterion = 18.985  cv(m.auto, k=\"loo\", method=\"Woodbury\") #> n-Fold Cross Validation #> method: Woodbury #> criterion: mse #> cross-validation criterion = 19.248 #> bias-adjusted cross-validation criterion = 19.248 #> full-sample criterion = 18.985 m.auto.glm <- glm(mpg ~ poly(horsepower, 2), data=Auto) boot::cv.glm(Auto, m.auto.glm)$delta #> [1] 19.248 19.248  microbenchmark::microbenchmark(   hatvalues = cv(m.auto, k=\"loo\"),   Woodbury = cv(m.auto, k=\"loo\", method=\"Woodbury\"),   naive = cv(m.auto, k=\"loo\", method=\"naive\"),   cv.glm = boot::cv.glm(Auto, m.auto.glm),   times=10 ) #> Unit: microseconds #>       expr      min       lq     mean   median       uq      max neval cld #>  hatvalues    982.4   1170.4   1217.3   1218.8   1267.9   1434.1    10 a   #>   Woodbury  10530.8  10624.2  11232.5  10927.0  11052.6  14672.2    10 a   #>      naive 221128.8 222305.4 240480.4 223625.3 279113.2 281829.2    10  b  #>     cv.glm 387227.5 392630.8 405857.8 393456.7 397338.6 460915.6    10   c"},{"path":"/articles/cv.html","id":"logistic-regression-for-the-mroz-data","dir":"Articles","previous_headings":"Examples","what":"Logistic regression for the Mroz data","title":"Cross-validation of regression models","text":"Mroz data set carData package (associated Fox & Weisberg, 2019) used several authors illustrate binary logistic regression; see, particular Fox & Weisberg (2019). data originally drawn U.S. Panel Study Income Dynamics pertain married women. cases data set: response variable logistic regression lfp, labor-force participation, factor coded \"yes\" \"\". remaining variables predictors: k5, number children 5 years old younger woman’s household; k618, number children 6 18 years old; age, years; wc, wife’s college attendance, \"yes\" \"\"; hc, husband’s college attendance; lwg, woman’s log wage rate employed, imputed wage rate, (variable Fox & Weisberg, 2019 show problematically defined); inc, family income, $1000s, exclusive wife’s income. use glm() function fit binary logistic regression Mroz data: addition usually summary output GLM, show result applying BayesRule() function cv package predictions derived fitted model. Bayes rule, predicts “success” binary regression model fitted probability success [.e., \\(\\phi = \\Pr(y = 1)\\)] \\(\\widehat{\\phi} \\ge .5\\) “failure” \\(\\widehat{\\phi} \\lt .5\\).4 first argument BayesRule() binary {0, 1} response, second argument predicted probability success. BayesRule() returns proportion predictions error, appropriate “cost” function. example, fitted logistic regression incorrectly predicts 31% responses; expect estimate optimistic given model used “predict” data fit. \"glm\" method cv() largely similar \"lm\" method, although default algorithm, selected explicitly method=\"exact\", refits model fold removed (thus equivalent method=\"naive\" \"lm\" models). generalized linear models, method=\"Woodbury\" (LOO CV) method=\"hatvalues\" provide approximate results (see last section vignette details): ensure two methods use 10 folds, specify seed R’s random-number generator explicitly; , common experience, \"exact\" \"Woodbury\" algorithms produce nearly identical results. CV estimates prediction error slightly higher estimate based cases. results applying LOO CV Mroz model, using exact approximate methods: number decimal digits shown, three methods produce identical results example. linear models, report timings various cv() methods computation LOO CV well cv.glm() function boot package (, recall, refits model case removed, thus comparable cv() method=\"exact\"): substantial time penalty associated exact computations.","code":"data(\"Mroz\", package=\"carData\") head(Mroz, 3) #>   lfp k5 k618 age wc hc    lwg   inc #> 1 yes  1    0  32 no no 1.2102 10.91 #> 2 yes  0    2  30 no no 0.3285 19.50 #> 3 yes  1    3  35 no no 1.5141 12.04 tail(Mroz, 3) #>     lfp k5 k618 age wc hc     lwg    inc #> 751  no  0    0  43 no no 0.88814  9.952 #> 752  no  0    0  60 no no 1.22497 24.984 #> 753  no  0    3  39 no no 0.85321 28.363 m.mroz <- glm(lfp ~ ., data=Mroz, family=binomial) summary(m.mroz) #>  #> Call: #> glm(formula = lfp ~ ., family = binomial, data = Mroz) #>  #> Coefficients: #>             Estimate Std. Error z value Pr(>|z|)     #> (Intercept)  3.18214    0.64438    4.94  7.9e-07 *** #> k5          -1.46291    0.19700   -7.43  1.1e-13 *** #> k618        -0.06457    0.06800   -0.95  0.34234     #> age         -0.06287    0.01278   -4.92  8.7e-07 *** #> wcyes        0.80727    0.22998    3.51  0.00045 *** #> hcyes        0.11173    0.20604    0.54  0.58762     #> lwg          0.60469    0.15082    4.01  6.1e-05 *** #> inc         -0.03445    0.00821   -4.20  2.7e-05 *** #> --- #> Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 #>  #> (Dispersion parameter for binomial family taken to be 1) #>  #>     Null deviance: 1029.75  on 752  degrees of freedom #> Residual deviance:  905.27  on 745  degrees of freedom #> AIC: 921.3 #>  #> Number of Fisher Scoring iterations: 4  BayesRule(ifelse(Mroz$lfp == \"yes\", 1, 0),            fitted(m.mroz, type=\"response\")) #> [1] 0.30677 cv(m.mroz, criterion=BayesRule, seed=248) #> 10-Fold Cross Validation #> method: exact #> criterion: BayesRule #> cross-validation criterion = 0.32404 #> bias-adjusted cross-validation criterion = 0.31952 #> full-sample criterion = 0.30677  cv(m.mroz, criterion=BayesRule, seed=248, method=\"Woodbury\") #> 10-Fold Cross Validation #> method: Woodbury #> criterion: BayesRule #> cross-validation criterion = 0.32404 #> bias-adjusted cross-validation criterion = 0.31926 #> full-sample criterion = 0.30677 cv(m.mroz, k=\"loo\", criterion=BayesRule) #> n-Fold Cross Validation #> method: exact #> criterion: BayesRule #> cross-validation criterion = 0.32005 #> bias-adjusted cross-validation criterion = 0.3183 #> full-sample criterion = 0.30677  cv(m.mroz, k=\"loo\", criterion=BayesRule, method=\"Woodbury\") #> n-Fold Cross Validation #> method: Woodbury #> criterion: BayesRule #> cross-validation criterion = 0.32005 #> bias-adjusted cross-validation criterion = 0.3183 #> full-sample criterion = 0.30677  cv(m.mroz, k=\"loo\", criterion=BayesRule, method=\"hatvalues\") #> n-Fold Cross Validation #> method: hatvalues #> criterion: BayesRule #> cross-validation criterion = 0.32005 microbenchmark::microbenchmark(   hatvalues=cv(m.mroz, k=\"loo\", criterion=BayesRule, method=\"hatvalues\"),   Woodbury=cv(m.mroz, k=\"loo\", criterion=BayesRule, method=\"Woodbury\"),   exact=cv(m.mroz, k=\"loo\", criterion=BayesRule),   cv.glm=boot::cv.glm(Mroz, m.mroz,                cost=BayesRule),   times=10) #> Unit: milliseconds #>       expr       min        lq      mean    median        uq       max neval #>  hatvalues    1.2922    1.3246    1.3657    1.3566    1.3914    1.4813    10 #>   Woodbury   39.2150   41.2499   41.7187   41.4697   42.4250   43.8037    10 #>      exact 1775.8396 1790.0738 1817.0953 1815.3605 1845.4016 1857.4810    10 #>     cv.glm 2054.0009 2094.6512 2138.3804 2145.9397 2181.9138 2194.4643    10 #>   cld #>  a    #>   b   #>    c  #>     d"},{"path":"/articles/cv.html","id":"cross-validating-model-selection","dir":"Articles","previous_headings":"","what":"Cross-validating model selection","title":"Cross-validation of regression models","text":"Hastie, Tibshirani, & Friedman (2009, sec. 7.10.2: “Wrong Right Way Cross-validation”), whole data used select fine-tune statistical model, subsequent cross-validation model intrinsically misleading, model selected fit whole data, including part data remains fold removed. following example similar spirit one employed Hastie et al. (2009). Suppose randomly generate \\(n = 1000\\) independent observations response variable variable \\(y \\sim N(\\mu = 10, \\sigma^2 = 0)\\), independently sample \\(1000\\) observations \\(p = 100\\) “predictors,” \\(x_1, \\ldots, x_{100}\\), \\(x_j \\sim N(0, 1)\\). response nothing predictors population linear-regression model \\(y_i = \\alpha + \\beta_1 x_{i1} + \\cdots + \\beta_{100} x_{,100} + \\varepsilon_i\\) \\(\\alpha = 10\\) \\(\\beta_j = 0\\).","code":"set.seed(123) # for reproducibility y <- rnorm(1000, mean=10) X <- matrix(rnorm(1000*100), 1000, 100) colnames(X) <- 1:100 head(y) #> [1]  9.4395  9.7698 11.5587 10.0705 10.1293 11.7151 X[1:5, 1:5] #>             1        2        3        4        5 #> [1,] -0.99580 -0.51160 -0.15031  0.19655 -0.49417 #> [2,] -1.03996  0.23694 -0.32776  0.65011  1.12759 #> [3,] -0.01798 -0.54159 -1.44817  0.67100 -1.14695 #> [4,] -0.13218  1.21923 -0.69728 -1.28416  1.48102 #> [5,] -2.54934  0.17414  2.59849 -2.02611  0.91619"},{"path":[]},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"John Fox. Author. Georges Monette. Author, maintainer.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Fox J, Monette G (2023). cv: Cross-Validation Regression Models. R package version 0.1.0.","code":"@Manual{,   title = {cv: Cross-Validation of Regression Models},   author = {John Fox and Georges Monette},   year = {2023},   note = {R package version 0.1.0}, }"},{"path":"/index.html","id":"cv-package-for-r-various-functions-for-cross-validation-of-regression-models","dir":"","previous_headings":"","what":"Cross-Validation of Regression Models","title":"Cross-Validation of Regression Models","text":"functions supplied package: cv() generic function default method computationally efficient \"lm\" \"glm\" methods. mse() (mean-squared error) BayesRule() cross-validation criteria (“cost functions”), suitable use cv(). cvSelect() cross-validates selection procedure regression model. selectStepAIC() model-selection procedure, suitable use cvSelect(), based stepAIC() function MASS package. time-package resides GitHub, anticipate eventually submitting CRAN. install package:","code":"if (!require(remotes)) install.packages(\"remotes\") remotes::install_github(\"gmonette/cv\", build_vignettes = TRUE)"},{"path":"/reference/cost-functions.html","id":null,"dir":"Reference","previous_headings":"","what":"Cost Functions for Fitted Regression Models — mse","title":"Cost Functions for Fitted Regression Models — mse","text":"Compute cost functions (cross-validation criteria) fitted regression models.","code":""},{"path":"/reference/cost-functions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cost Functions for Fitted Regression Models — mse","text":"","code":"mse(y, yhat)  BayesRule(y, yhat)  BayesRule2(y, yhat)"},{"path":"/reference/cost-functions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cost Functions for Fitted Regression Models — mse","text":"y response yhat fitted value","code":""},{"path":"/reference/cost-functions.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cost Functions for Fitted Regression Models — mse","text":"Two cost functions (cross-validation criteria) provided: (1) mse() returns mean-squared error prediction numeric response variable y predictions yhat. (2) BayesRule() BayesRule2() report proportion correct predictions dichotomous response variable y, assumed coded 0 1. yhat values predicted probabilities rounded 0 1. distinction BayesRule() BayesRule2() former checks y values either 0 1 yhat values 0 1, latter therefore faster.","code":""},{"path":"/reference/cost-functions.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Cost Functions for Fitted Regression Models — mse","text":"mse(): Mean-square error BayesRule(): Bayes Rule binary response BayesRule2(): Bayes rule binary response (without bounds checking)","code":""},{"path":"/reference/cv.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-Validate Regression Models — cv.merMod","title":"Cross-Validate Regression Models — cv.merMod","text":"parallelized generic k-fold (including n-fold, .e., leave-one-) cross-validation function, default method, specific methods linear generalized-linear models can much computationally efficient.","code":""},{"path":"/reference/cv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-Validate Regression Models — cv.merMod","text":"","code":"# S3 method for merMod cv(   model,   data = insight::get_data(model),   criterion = mse,   k = nrow(clusters),   seed,   parallel = FALSE,   ncores = parallelly::availableCores(logical = FALSE),   clusterVariables,   ... )  cv(model, data, criterion, k, seed, ...)  # S3 method for default cv(   model,   data = insight::get_data(model),   criterion = mse,   k = 10,   seed,   parallel = FALSE,   ncores = parallelly::availableCores(logical = FALSE),   method = NULL,   ... )  # S3 method for cv print(x, digits = getOption(\"digits\"), ...)  # S3 method for lm cv(   model,   data = insight::get_data(model),   criterion = mse,   k = 10,   seed,   method = c(\"auto\", \"hatvalues\", \"Woodbury\", \"naive\"),   parallel = FALSE,   ncores = parallelly::availableCores(logical = FALSE),   ... )  # S3 method for glm cv(   model,   data = insight::get_data(model),   criterion = mse,   k = 10,   seed,   method = c(\"exact\", \"hatvalues\", \"Woodbury\"),   parallel = FALSE,   ncores = parallelly::availableCores(logical = FALSE),   ... )"},{"path":"/reference/cv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-Validate Regression Models — cv.merMod","text":"model regression model object (see Details). data data frame model fit (usually necessary) criterion cross-validation criterion function form f(y, yhat) y observed values response yhat predicted values; default mse (mean-squared error) k perform k-fold cross-validation (default 10); k may number \"loo\" \"n\" n-fold (leave-one-) cross-validation. seed R's random number generator; optional, supplied random seed selected saved; needed n-fold cross-validation parallel computations parallel? (default FALSE) ncores number cores use parallel computations (default number physical cores detected) clusterVariables character vector names variables defining clusters mixed model nested random effects ... match generic method computational method apply linear (.e. \"lm\") model generalized linear (.e., \"glm\") model. See Details explanation available options. x cv object printed digits significant digits printing, default taken \"digits\" option","code":""},{"path":"/reference/cv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-Validate Regression Models — cv.merMod","text":"\"cv\" object cross-validation criterion averaged across folds, bias-adjusted averaged CV criterion, criterion applied model fit full data set, initial value R's RNG seed. methods return subset components may add additional information.","code":""},{"path":"/reference/cv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-Validate Regression Models — cv.merMod","text":"default method uses update() refit model fold, work appropriate update() predict() methods default method getResponse() works getResponse() method supplied. \"lm\" \"glm\" methods can use much faster computational algorithms, selected method argument. linear-model method accommodates weighted linear models. classes models, leave-one-(n-fold) case, fitted values folds can computed hat-values via method=\"hatvalues\" without refitting model; GLMs, method approximate, LMs exact. classes models, one case omitted fold, fitted values may obtained without refitting model exploiting Woodbury matrix identity via method=\"Woodbury\". hatvalues, method exact LMs approximate GLMs. default linear models method=\"auto\", equivalent method=\"hatvalues\" n-fold cross-validation method=\"Woodbury\" otherwise; method=\"naive\" refits model via update() generally much slower. default generalized linear models method=\"exact\", employs update().","code":""},{"path":"/reference/cv.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Cross-Validate Regression Models — cv.merMod","text":"cv(merMod): merMod method cv(default): default method cv(lm): \"lm\" method cv(glm): \"glm\" method","code":""},{"path":"/reference/cv.html","id":"methods-by-generic-","dir":"Reference","previous_headings":"","what":"Methods (by generic)","title":"Cross-Validate Regression Models — cv.merMod","text":"print(cv): print() method","code":""},{"path":"/reference/cv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-Validate Regression Models — cv.merMod","text":"","code":"data(\"Auto\", package=\"ISLR2\") m.auto <- lm(mpg ~ horsepower, data=Auto) cv(m.auto,  k=\"loo\") #> n-Fold Cross Validation #> method: hatvalues #> criterion: mse #> cross-validation criterion = 24.23151 cv(m.auto, seed=1234) #> R RNG seed set to 1234 #> 10-Fold Cross Validation #> method: Woodbury #> criterion: mse #> cross-validation criterion = 24.3794 #> bias-adjusted cross-validation criterion = 24.35646 #> full-sample criterion = 23.94366   data(\"Caravan\", package=\"ISLR2\") m.caravan <- glm(Purchase ~ ., data=Caravan[1:2500, ], family=binomial) #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred cv(m.caravan, k=5, criterion=BayesRule, seed=123) #> R RNG seed set to 123 #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: prediction from rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: prediction from rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: prediction from rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: prediction from rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred #> Warning: prediction from rank-deficient fit; attr(*, \"non-estim\") has doubtful cases #> 5-Fold Cross Validation #> method: exact #> criterion: BayesRule #> cross-validation criterion = 0.0648 #> bias-adjusted cross-validation criterion = 0.06512 #> full-sample criterion = 0.0576"},{"path":"/reference/cvSelect.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-Validate a Model-Selection Procedure — cvSelect","title":"Cross-Validate a Model-Selection Procedure — cvSelect","text":"generic function cross-validate model-selection procedure, along procedure applies stepAIC() model-selection function MASS package.","code":""},{"path":"/reference/cvSelect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-Validate a Model-Selection Procedure — cvSelect","text":"","code":"cvSelect(   procedure,   data,   k = 10,   seed,   parallel = FALSE,   ncores = parallelly::availableCores(logical = FALSE),   ... )  selectStepAIC(data, indices, model, criterion = mse, k. = 2, ...)"},{"path":"/reference/cvSelect.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-Validate a Model-Selection Procedure — cvSelect","text":"procedure model-selection procedure function (see Details). data full data frame model selection. k perform k-fold cross-validation (default 10); k may number \"loo\" \"n\" n-fold (leave-one-) cross-validation. seed R's random number generator; used n-fold cross-validation. parallel computations parallel? (default FALSE), ncores number cores use parallel computations (default number physical cores detected). ... arguments passed procedure(). indices indices cases data defining current fold. model regression model object fit data. criterion CV criterion function. k. k argument stepAIC() (note period k.).","code":""},{"path":"/reference/cvSelect.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-Validate a Model-Selection Procedure — cvSelect","text":"cvSelect() return \"cv\" object CV criterion averaged across folds, bias-adjusted averaged CV criterion, criterion applied model fit full data set, initial value R's RNG seed.","code":""},{"path":"/reference/cvSelect.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Cross-Validate a Model-Selection Procedure — cvSelect","text":"model-selection function supplied procedure argument cvSelect() accept following arguments: data set data argument cvSelect(). indices indices rows data defining current fold; missing, model-selection procedure applied full data. arguments passed via ... cvSelect(). procedure() return two-element vector result applying cross-validation criterion cases current fold model deleting fold, cases model deleting current fold. indices argument missing, procedure() returns cross-validation criterion cases based model fit cases. example model-selection function procedure argument, see code selectStepAIC().","code":""},{"path":"/reference/cvSelect.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"Cross-Validate a Model-Selection Procedure — cvSelect","text":"cvSelect(): apply cross-validation model-selection procedure. selectStepAIC(): select model using stepAIC() function MASS package.","code":""},{"path":[]},{"path":"/reference/cvSelect.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-Validate a Model-Selection Procedure — cvSelect","text":"","code":"data(\"Auto\", package=\"ISLR2\") m.auto <- lm(mpg ~ . - name - origin, data=Auto) cvSelect(selectStepAIC, Auto, seed=123, model=m.auto) #> R RNG seed set to 123 #> 10-Fold Cross Validation #> cross-validation criterion = 11.87795 #> bias-adjusted cross-validation criterion = 11.8753 #> full-sample criterion = 11.65549  cvSelect(selectStepAIC, Auto, seed=123, model=m.auto,          k.=log(nrow(Auto))) # via BIC #> R RNG seed set to 123 #> 10-Fold Cross Validation #> cross-validation criterion = 11.7953 #> bias-adjusted cross-validation criterion = 11.78791 #> full-sample criterion = 11.65549"},{"path":"/reference/getResponse.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Response Variable(s) — getResponse","title":"Extract Response Variable(s) — getResponse","text":"Generic function extract response variable(s) fitted model.","code":""},{"path":"/reference/getResponse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Response Variable(s) — getResponse","text":"","code":"getResponse(model, ...)  # S3 method for default getResponse(model, ...)"},{"path":"/reference/getResponse.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Response Variable(s) — getResponse","text":"model fitted model ... additional parameters specific methods","code":""},{"path":"/reference/getResponse.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Response Variable(s) — getResponse","text":"vector matrix containing values response variable(s)","code":""},{"path":"/reference/getResponse.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract Response Variable(s) — getResponse","text":"supplied default method returns model$y component model object exists otherwise result model.response(model.frame(model)), checking either case whether result numeric.","code":""},{"path":"/reference/getResponse.html","id":"methods-by-class-","dir":"Reference","previous_headings":"","what":"Methods (by class)","title":"Extract Response Variable(s) — getResponse","text":"getResponse(default): default method","code":""},{"path":"/reference/getResponse.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Response Variable(s) — getResponse","text":"","code":"fit <- lm(cbind(hp, mpg) ~ gear, mtcars)     getResponse(fit) #>                      hp  mpg #> Mazda RX4           110 21.0 #> Mazda RX4 Wag       110 21.0 #> Datsun 710           93 22.8 #> Hornet 4 Drive      110 21.4 #> Hornet Sportabout   175 18.7 #> Valiant             105 18.1 #> Duster 360          245 14.3 #> Merc 240D            62 24.4 #> Merc 230             95 22.8 #> Merc 280            123 19.2 #> Merc 280C           123 17.8 #> Merc 450SE          180 16.4 #> Merc 450SL          180 17.3 #> Merc 450SLC         180 15.2 #> Cadillac Fleetwood  205 10.4 #> Lincoln Continental 215 10.4 #> Chrysler Imperial   230 14.7 #> Fiat 128             66 32.4 #> Honda Civic          52 30.4 #> Toyota Corolla       65 33.9 #> Toyota Corona        97 21.5 #> Dodge Challenger    150 15.5 #> AMC Javelin         150 15.2 #> Camaro Z28          245 13.3 #> Pontiac Firebird    175 19.2 #> Fiat X1-9            66 27.3 #> Porsche 914-2        91 26.0 #> Lotus Europa        113 30.4 #> Ford Pantera L      264 15.8 #> Ferrari Dino        175 19.7 #> Maserati Bora       335 15.0 #> Volvo 142E          109 21.4"},{"path":"/news/index.html","id":"cv-010","dir":"Changelog","previous_headings":"","what":"cv 0.1.0","title":"cv 0.1.0","text":"Initial version.","code":""}]
